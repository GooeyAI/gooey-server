import requests
import streamlit as st
from pydantic import BaseModel

from daras_ai.face_restoration import map_parallel, gfpgan
from daras_ai.image_input import (
    upload_file_from_bytes,
    safe_filename,
    upload_file_hq,
    resize_img_pad,
)
from daras_ai_v2 import stable_diffusion
from daras_ai_v2.base import BasePage
from daras_ai_v2.enum_selector_widget import enum_selector
from daras_ai_v2.image_segmentation import dis, u2net
from daras_ai_v2.stable_diffusion import InpaintingModels


class ObjectInpaintingPage(BasePage):
    title = "An Object in Any Scene"
    slug = "ObjectInpainting"

    class RequestModel(BaseModel):
        input_image: str
        text_prompt: str

        num_outputs: int = 1
        quality: int = 50

        obj_scale: float = 0.30
        obj_pos_x: float = 0.4
        obj_pos_y: float = 0.45

        output_width: int = 512
        output_height: int = 512

        selected_model: str = InpaintingModels.jack_qiao.name

    class ResponseModel(BaseModel):
        resized_image: str
        obj_mask: str
        # diffusion_images: list[str]
        output_images: list[str]

    def render_form(self):
        with st.form("my_form"):
            st.write(
                """
                ### Prompt
                Describe the character that you'd like to generate. 
                """
            )
            st.text_input(
                "text_prompt",
                label_visibility="collapsed",
                key="text_prompt",
                placeholder="Iron man",
            )

            st.write(
                """
                ### Object Photo
                Give us a photo of yourself, or anyone else
                """
            )
            st.file_uploader(
                "input_file",
                label_visibility="collapsed",
                key="input_file",
            )
            st.caption(
                "By uploading an image, you agree to Gooey.AI's [Privacy Policy](https://dara.network/privacy)"
            )

            submitted = st.form_submit_button("üèÉ‚Äç Submit")

        text_prompt = st.session_state.get("text_prompt")
        input_file = st.session_state.get("input_file")
        input_image = st.session_state.get("input_image")
        input_image_or_file = input_file or input_image

        # form validation
        if submitted and not (text_prompt and input_image_or_file):
            st.error("Please provide a Prompt and a Object Photo", icon="‚ö†Ô∏è")
            return False

        # upload input file if submitted
        if submitted:
            input_file = st.session_state.get("input_file")
            if input_file:
                st.session_state["input_image"] = upload_file_hq(input_file)

        return submitted

    def render_settings(self):
        selected_model = enum_selector(
            InpaintingModels,
            label="Image Model",
            key="selected_model",
        )

        col1, col2 = st.columns(2, gap="medium")
        with col1:
            st.slider(
                label="# of Outputs",
                key="num_outputs",
                min_value=1,
                max_value=4,
            )
        with col2:
            if selected_model != InpaintingModels.dall_e.name:
                st.slider(
                    label="Quality",
                    key="quality",
                    min_value=10,
                    max_value=200,
                    step=10,
                )
            else:
                st.empty()

        st.write(
            """
            ### Output Resolution
            """
        )
        col1, col2, col3 = st.columns([10, 1, 10])
        with col1:
            output_width = st.slider(
                "Width",
                key="output_width",
                min_value=512,
                max_value=1024,
                step=128,
            )
        with col2:
            st.write("X")
        with col3:
            output_height = st.slider(
                "Height",
                key="output_height",
                min_value=512,
                max_value=1024,
                step=128,
            )

        st.write(
            """
            ### Object Repositioning Settings
            """
        )
        col1, col2, col3 = st.columns(3)
        obj_scale = col1.slider(
            "Scale",
            min_value=0.1,
            max_value=1.0,
            key="obj_scale",
        )
        pos_x = col2.slider(
            "Position X",
            min_value=0.0,
            max_value=1.0,
            key="obj_pos_x",
        )
        pos_y = col3.slider(
            "Position Y",
            min_value=0.0,
            max_value=1.0,
            key="obj_pos_y",
        )

        # # show an example image
        # img_cv2 = cv2.imread("static/obj.png")
        #
        # # extract obj
        # img, mask = extract_and_reposition_face_cv2(
        #     img_cv2,
        #     out_size=(output_width, output_height),
        #     out_face_scale=face_scale,
        #     out_pos_x=pos_x,
        #     out_pos_y=pos_y,
        # )
        #
        # # draw rule of 3rds
        # color = (200, 200, 200)
        # stroke = 2
        # img_y, img_x, _ = img.shape
        # for i in range(2):
        #     pos = (img_y // 3) * (i + 1)
        #     cv2.line(img, (0, pos), (img_x, pos), color, stroke)
        #
        #     pos = (img_x // 3) * (i + 1)
        #     cv2.line(img, (pos, 0), (pos, img_y), color, stroke)
        #
        # st.image(img, width=300)

    def render_output(self):
        text_prompt = st.session_state.get("text_prompt", "")
        input_file = st.session_state.get("input_file")
        input_image = st.session_state.get("input_image")
        input_image_or_file = input_image or input_file
        output_images = st.session_state.get("output_images")

        col1, col2 = st.columns(2)

        with col1:
            if input_image_or_file:
                st.image(input_image_or_file, caption="Object Photo")
            else:
                st.empty()

        with col2:
            if output_images:
                for url in output_images:
                    st.image(url, caption=f"‚Äú{text_prompt}‚Äù")
            else:
                st.empty()

        with st.expander("Steps"):
            col1, col2, col3 = st.columns(3)

            with col1:
                if input_image_or_file:
                    st.image(input_image_or_file, caption="Input Image")
                else:
                    st.empty()

            with col2:
                resized_image = st.session_state.get("resized_image")
                if resized_image:
                    st.image(resized_image, caption="Repositioned Object")
                else:
                    st.empty()

                obj_mask = st.session_state.get("obj_mask")
                if obj_mask:
                    st.image(obj_mask, caption="Object Mask")
                else:
                    st.empty()

            with col3:
                diffusion_images = st.session_state.get("output_images")
                if diffusion_images:
                    for url in diffusion_images:
                        st.image(url, caption=f"Stable Diffusion - ‚Äú{text_prompt}‚Äù")
                else:
                    st.empty()

    def run(self, state: dict):
        request = self.RequestModel.parse_obj(state)

        yield "Running Image Segmentation..."

        img_bytes = requests.get(request.input_image).content

        re_img_bytes = resize_img_pad(
            img_bytes, (request.output_width, request.output_height)
        )

        state["resized_image"] = upload_file_from_bytes("re_img.png", re_img_bytes)

        obj_mask_bytes = u2net(state["resized_image"])
        state["obj_mask"] = upload_file_from_bytes("obj_mask.png", obj_mask_bytes)

        yield f"Generating Image..."

        diffusion_images = stable_diffusion.inpainting(
            selected_model=request.selected_model,
            prompt=request.text_prompt,
            num_outputs=request.num_outputs,
            edit_image=state["resized_image"],
            edit_image_bytes=re_img_bytes,
            mask=state["obj_mask"],
            mask_bytes=obj_mask_bytes,
            num_inference_steps=request.quality,
            width=request.output_width,
            height=request.output_height,
        )
        state["output_images"] = diffusion_images

    def render_example(self, state: dict):
        col1, col2 = st.columns(2)
        with col1:
            input_image = state.get("input_image")
            if input_image:
                st.image(input_image, caption="Input Image")
        with col2:
            output_images = state.get("output_images")
            if output_images:
                for img in output_images:
                    st.image(img, caption=state.get("text_prompt", ""))


if __name__ == "__main__":
    ObjectInpaintingPage().render()
